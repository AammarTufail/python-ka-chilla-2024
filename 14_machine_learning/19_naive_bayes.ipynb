{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE Bayes algorithm\n",
    "\n",
    "Naive Bayes Algorithm is a classification algorithm based on Bayes Theorem. It is called naive because it assumes that the features in a dataset are independent of each other. This assumption is not true in real life but it simplifies the computation and gives good results in most of the cases.\n",
    "\n",
    "## Bayes Theorem\n",
    "\n",
    "Bayes Theorem is a mathematical formula used for calculating conditional probability. It is defined as:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "where A and B are events and P(B) != 0\n",
    "\n",
    "## Naive Bayes Algorithm\n",
    "\n",
    "Naive Bayes Algorithm is based on Bayes Theorem. It is defined as:\n",
    "\n",
    "$$P(y|x_1,x_2,...,x_n) = \\frac{P(x_1,x_2,...,x_n|y)P(y)}{P(x_1,x_2,...,x_n)}$$\n",
    "\n",
    "where y is the class variable and x1, x2, ..., xn are the features.\n",
    "\n",
    "The algorithm assumes that the features are independent of each other. So, the above equation can be written as:\n",
    "\n",
    "$$P(y|x_1,x_2,...,x_n) = \\frac{P(x_1|y)P(x_2|y)...P(x_n|y)P(y)}{P(x_1,x_2,...,x_n)}$$\n",
    "\n",
    "The denominator is constant for a given input. So, the equation can be written as:\n",
    "\n",
    "$$P(y|x_1,x_2,...,x_n) \\propto P(x_1|y)P(x_2|y)...P(x_n|y)P(y)$$\n",
    "\n",
    "The class with the highest probability is the output of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = sns.load_dataset('iris')\n",
    "print(df.head())\n",
    "X = df.drop('species', axis=1)\n",
    "y = df['species']\n",
    "\n",
    "# train test split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  1.0\n",
      "Confusion Matrix: \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       1.00      1.00      1.00        11\n",
      "   virginica       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model initialize\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# train the model\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# predict the test data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.9736842105263158\n",
      "Confusion Matrix: \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  1 11]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.92      1.00      0.96        11\n",
      "   virginica       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.97      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model initialize\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# train the model\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "# predict the test data\n",
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.2894736842105263\n",
      "Confusion Matrix: \n",
      " [[ 0 15  0]\n",
      " [ 0 11  0]\n",
      " [ 0 12  0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       0.00      0.00      0.00        15\n",
      "  versicolor       0.29      1.00      0.45        11\n",
      "   virginica       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.29        38\n",
      "   macro avg       0.10      0.33      0.15        38\n",
      "weighted avg       0.08      0.29      0.13        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model initialize\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# train the model\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "# predict the test data\n",
    "y_pred = bnb.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
